{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7bca75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is \n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, cross_val_predict\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, classification_report\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, f1_score, roc_curve, roc_auc_score \n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59676841",
   "metadata": {},
   "outputs": [],
   "source": [
    "url= \"brain_stroke_in_numeric_without_useless_data.csv\"\n",
    "brain = pd.read_csv(url)\n",
    "brain = brain.drop(brain.columns[0], axis=1)\n",
    "X = brain.iloc[:, :8]\n",
    "y = brain.iloc[:, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bacb845b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5feeaaf4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9478260869565217\n"
     ]
    }
   ],
   "source": [
    "per_clf = Perceptron(max_iter=1000, tol=1e-3, random_state=42)\n",
    "y_pred = per_clf.fit(X_train, y_train).predict(X_test)\n",
    "print(\"Accuracy:\",accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a79aca1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Cross Validation score :0.8125424035833086\n",
      "TN: 2778, FP: 538, FN: 116, TP: 54\n",
      "Precision: 0.09121621621621621\n",
      "Recall: 0.3176470588235294\n",
      "f1 score: 0.14173228346456693\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "score = cross_val_score(per_clf, X_train, y_train, cv=kf, scoring='accuracy')\n",
    "print(\"Accuracy Cross Validation score :{}\".format(score.mean()))\n",
    "y_train_pred = cross_val_predict(per_clf, X_train, y_train, cv=kf)\n",
    "tn, fp, fn, tp = confusion_matrix(y_train, y_train_pred).ravel()\n",
    "print(\"TN: %.0f\" % tn + \", FP: %.0f\" % fp + \", FN: %.0f\" % fn + \", TP: %.0f\" % tp)\n",
    "print(\"Precision:\",precision_score(y_train, y_train_pred))\n",
    "print(\"Recall:\", recall_score(y_train, y_train_pred))\n",
    "print(\"f1 score:\", f1_score(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08640f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we want to change the number and size of layers we need to use the MLPCClassifier from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58a0a23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9491638795986622\n"
     ]
    }
   ],
   "source": [
    "mlp_clf = MLPClassifier(random_state=1)\n",
    "y_pred = mlp_clf.fit(X_train, y_train).predict(X_test)\n",
    "print(\"Accuracy:\",accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16777981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Cross Validation score :0.9503647531535092\n",
      "TN: 3313, FP: 3, FN: 170, TP: 0\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "f1 score: 0.0\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "score = cross_val_score(mlp_clf, X_train, y_train, cv=kf, scoring='accuracy')\n",
    "print(\"Accuracy Cross Validation score :{}\".format(score.mean()))\n",
    "\n",
    "y_train_pred = cross_val_predict(mlp_clf, X_train, y_train, cv=kf)\n",
    "tn, fp, fn, tp = confusion_matrix(y_train, y_train_pred).ravel()\n",
    "print(\"TN: %.0f\" % tn + \", FP: %.0f\" % fp + \", FN: %.0f\" % fn + \", TP: %.0f\" % tp)\n",
    "print(\"Precision:\",precision_score(y_train, y_train_pred))\n",
    "print(\"Recall:\", recall_score(y_train, y_train_pred))\n",
    "print(\"f1 score:\", f1_score(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18c595a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate change "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f33a5b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TP</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precission</th>\n",
       "      <th>Recall</th>\n",
       "      <th>AURC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.949164</td>\n",
       "      <td>3313.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.499548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy      TN   FP     FN   TP  Sensitivity  Specificity  Precission  \\\n",
       "0  0.949164  3313.0  3.0  170.0  0.0          0.0     0.999095         0.0   \n",
       "\n",
       "   Recall      AURC  \n",
       "0     0.0  0.499548  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = [\n",
    "    MLPClassifier(random_state=1),\n",
    "\n",
    "    ]\n",
    "clf_columns = []\n",
    "clf_compare = pd.DataFrame(columns = clf_columns)\n",
    "\n",
    "row_index = 0\n",
    "for alg in clf:\n",
    "        \n",
    "    predicted = alg.fit(X_train, y_train).predict(X_test)\n",
    "    kf = KFold(n_splits=10)\n",
    "    y_train_pred = cross_val_predict(mlp_clf, X_train, y_train, cv=kf)\n",
    "    clf_name = alg.__class__.__name__\n",
    "    clf_compare.loc[row_index, 'Accuracy'] = accuracy_score(y_test, predicted )\n",
    "    tn, fp, fn, tp = confusion_matrix(y_train, y_train_pred).ravel()\n",
    "    clf_compare.loc[row_index, 'TN'] = tn\n",
    "    clf_compare.loc[row_index, 'FP'] = fp\n",
    "    clf_compare.loc[row_index, 'FN'] = fn\n",
    "    clf_compare.loc[row_index, 'TP'] = tp\n",
    "    clf_compare.loc[row_index, 'Sensitivity'] = tp / (tp + fn)\n",
    "    clf_compare.loc[row_index, 'Specificity'] = tn / (tn + fp)\n",
    "    clf_compare.loc[row_index, 'Precission'] = precision_score(y_train, y_train_pred, zero_division=0)\n",
    "    clf_compare.loc[row_index, 'Recall'] = recall_score(y_train, y_train_pred, zero_division=0)\n",
    "    fpr, tpr, thresholds = roc_curve(y_train, y_train_pred)\n",
    "    clf_compare.loc[row_index, 'AURC'] = roc_auc_score(y_train, y_train_pred)\n",
    "    row_index+=1\n",
    "    \n",
    "clf_compare.sort_values(by = ['Accuracy'], ascending = False, inplace = True)    \n",
    "clf_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ede3702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a280d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = [\n",
    "    MLPClassifier(random_state=1),\n",
    "\n",
    "    ]\n",
    "clf_columns = []\n",
    "clf_compare = pd.DataFrame(columns = clf_columns)\n",
    "\n",
    "row_index = 0\n",
    "for alg in clf:\n",
    "        \n",
    "    predicted = alg.fit(X_train, y_train).predict(X_test)\n",
    "    kf = KFold(n_splits=10)\n",
    "    y_train_pred = cross_val_predict(mlp_clf, X_train, y_train, cv=kf)\n",
    "    clf_name = alg.__class__.__name__\n",
    "    clf_compare.loc[row_index, 'Accuracy'] = accuracy_score(y_test, predicted )\n",
    "    tn, fp, fn, tp = confusion_matrix(y_train, y_train_pred).ravel()\n",
    "    clf_compare.loc[row_index, 'TN'] = tn\n",
    "    clf_compare.loc[row_index, 'FP'] = fp\n",
    "    clf_compare.loc[row_index, 'FN'] = fn\n",
    "    clf_compare.loc[row_index, 'TP'] = tp\n",
    "    clf_compare.loc[row_index, 'Sensitivity'] = tp / (tp + fn)\n",
    "    clf_compare.loc[row_index, 'Specificity'] = tn / (tn + fp)\n",
    "    clf_compare.loc[row_index, 'Precission'] = precision_score(y_train, y_train_pred, zero_division=0)\n",
    "    clf_compare.loc[row_index, 'Recall'] = recall_score(y_train, y_train_pred, zero_division=0)\n",
    "    fpr, tpr, thresholds = roc_curve(y_train, y_train_pred)\n",
    "    clf_compare.loc[row_index, 'AURC'] = roc_auc_score(y_train, y_train_pred)\n",
    "    row_index+=1\n",
    "    \n",
    "clf_compare.sort_values(by = ['Accuracy'], ascending = False, inplace = True)    \n",
    "clf_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232da1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e45b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = [\n",
    "    MLPClassifier(random_state=1),\n",
    "\n",
    "    ]\n",
    "clf_columns = []\n",
    "clf_compare = pd.DataFrame(columns = clf_columns)\n",
    "\n",
    "row_index = 0\n",
    "for alg in clf:\n",
    "        \n",
    "    predicted = alg.fit(X_train, y_train).predict(X_test)\n",
    "    kf = KFold(n_splits=10)\n",
    "    y_train_pred = cross_val_predict(mlp_clf, X_train, y_train, cv=kf)\n",
    "    clf_name = alg.__class__.__name__\n",
    "    clf_compare.loc[row_index, 'Accuracy'] = accuracy_score(y_test, predicted )\n",
    "    tn, fp, fn, tp = confusion_matrix(y_train, y_train_pred).ravel()\n",
    "    clf_compare.loc[row_index, 'TN'] = tn\n",
    "    clf_compare.loc[row_index, 'FP'] = fp\n",
    "    clf_compare.loc[row_index, 'FN'] = fn\n",
    "    clf_compare.loc[row_index, 'TP'] = tp\n",
    "    clf_compare.loc[row_index, 'Sensitivity'] = tp / (tp + fn)\n",
    "    clf_compare.loc[row_index, 'Specificity'] = tn / (tn + fp)\n",
    "    clf_compare.loc[row_index, 'Precission'] = precision_score(y_train, y_train_pred, zero_division=0)\n",
    "    clf_compare.loc[row_index, 'Recall'] = recall_score(y_train, y_train_pred, zero_division=0)\n",
    "    fpr, tpr, thresholds = roc_curve(y_train, y_train_pred)\n",
    "    clf_compare.loc[row_index, 'AURC'] = roc_auc_score(y_train, y_train_pred)\n",
    "    row_index+=1\n",
    "    \n",
    "clf_compare.sort_values(by = ['Accuracy'], ascending = False, inplace = True)    \n",
    "clf_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e337a147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f73203",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = [\n",
    "    MLPClassifier(random_state=1),\n",
    "\n",
    "    ]\n",
    "clf_columns = []\n",
    "clf_compare = pd.DataFrame(columns = clf_columns)\n",
    "\n",
    "row_index = 0\n",
    "for alg in clf:\n",
    "        \n",
    "    predicted = alg.fit(X_train, y_train).predict(X_test)\n",
    "    kf = KFold(n_splits=10)\n",
    "    y_train_pred = cross_val_predict(mlp_clf, X_train, y_train, cv=kf)\n",
    "    clf_name = alg.__class__.__name__\n",
    "    clf_compare.loc[row_index, 'Accuracy'] = accuracy_score(y_test, predicted )\n",
    "    tn, fp, fn, tp = confusion_matrix(y_train, y_train_pred).ravel()\n",
    "    clf_compare.loc[row_index, 'TN'] = tn\n",
    "    clf_compare.loc[row_index, 'FP'] = fp\n",
    "    clf_compare.loc[row_index, 'FN'] = fn\n",
    "    clf_compare.loc[row_index, 'TP'] = tp\n",
    "    clf_compare.loc[row_index, 'Sensitivity'] = tp / (tp + fn)\n",
    "    clf_compare.loc[row_index, 'Specificity'] = tn / (tn + fp)\n",
    "    clf_compare.loc[row_index, 'Precission'] = precision_score(y_train, y_train_pred, zero_division=0)\n",
    "    clf_compare.loc[row_index, 'Recall'] = recall_score(y_train, y_train_pred, zero_division=0)\n",
    "    fpr, tpr, thresholds = roc_curve(y_train, y_train_pred)\n",
    "    clf_compare.loc[row_index, 'AURC'] = roc_auc_score(y_train, y_train_pred)\n",
    "    row_index+=1\n",
    "    \n",
    "clf_compare.sort_values(by = ['Accuracy'], ascending = False, inplace = True)    \n",
    "clf_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fbb494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd95b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = [\n",
    "    MLPClassifier(random_state=1),\n",
    "\n",
    "    ]\n",
    "clf_columns = []\n",
    "clf_compare = pd.DataFrame(columns = clf_columns)\n",
    "\n",
    "row_index = 0\n",
    "for alg in clf:\n",
    "        \n",
    "    predicted = alg.fit(X_train, y_train).predict(X_test)\n",
    "    kf = KFold(n_splits=10)\n",
    "    y_train_pred = cross_val_predict(mlp_clf, X_train, y_train, cv=kf)\n",
    "    clf_name = alg.__class__.__name__\n",
    "    clf_compare.loc[row_index, 'Accuracy'] = accuracy_score(y_test, predicted )\n",
    "    tn, fp, fn, tp = confusion_matrix(y_train, y_train_pred).ravel()\n",
    "    clf_compare.loc[row_index, 'TN'] = tn\n",
    "    clf_compare.loc[row_index, 'FP'] = fp\n",
    "    clf_compare.loc[row_index, 'FN'] = fn\n",
    "    clf_compare.loc[row_index, 'TP'] = tp\n",
    "    clf_compare.loc[row_index, 'Sensitivity'] = tp / (tp + fn)\n",
    "    clf_compare.loc[row_index, 'Specificity'] = tn / (tn + fp)\n",
    "    clf_compare.loc[row_index, 'Precission'] = precision_score(y_train, y_train_pred, zero_division=0)\n",
    "    clf_compare.loc[row_index, 'Recall'] = recall_score(y_train, y_train_pred, zero_division=0)\n",
    "    fpr, tpr, thresholds = roc_curve(y_train, y_train_pred)\n",
    "    clf_compare.loc[row_index, 'AURC'] = roc_auc_score(y_train, y_train_pred)\n",
    "    row_index+=1\n",
    "    \n",
    "clf_compare.sort_values(by = ['Accuracy'], ascending = False, inplace = True)    \n",
    "clf_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296eccb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7800377",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = [\n",
    "    MLPClassifier(random_state=1),\n",
    "\n",
    "    ]\n",
    "clf_columns = []\n",
    "clf_compare = pd.DataFrame(columns = clf_columns)\n",
    "\n",
    "row_index = 0\n",
    "for alg in clf:\n",
    "        \n",
    "    predicted = alg.fit(X_train, y_train).predict(X_test)\n",
    "    kf = KFold(n_splits=10)\n",
    "    y_train_pred = cross_val_predict(mlp_clf, X_train, y_train, cv=kf)\n",
    "    clf_name = alg.__class__.__name__\n",
    "    clf_compare.loc[row_index, 'Accuracy'] = accuracy_score(y_test, predicted )\n",
    "    tn, fp, fn, tp = confusion_matrix(y_train, y_train_pred).ravel()\n",
    "    clf_compare.loc[row_index, 'TN'] = tn\n",
    "    clf_compare.loc[row_index, 'FP'] = fp\n",
    "    clf_compare.loc[row_index, 'FN'] = fn\n",
    "    clf_compare.loc[row_index, 'TP'] = tp\n",
    "    clf_compare.loc[row_index, 'Sensitivity'] = tp / (tp + fn)\n",
    "    clf_compare.loc[row_index, 'Specificity'] = tn / (tn + fp)\n",
    "    clf_compare.loc[row_index, 'Precission'] = precision_score(y_train, y_train_pred, zero_division=0)\n",
    "    clf_compare.loc[row_index, 'Recall'] = recall_score(y_train, y_train_pred, zero_division=0)\n",
    "    fpr, tpr, thresholds = roc_curve(y_train, y_train_pred)\n",
    "    clf_compare.loc[row_index, 'AURC'] = roc_auc_score(y_train, y_train_pred)\n",
    "    row_index+=1\n",
    "    \n",
    "clf_compare.sort_values(by = ['Accuracy'], ascending = False, inplace = True)    \n",
    "clf_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9feb34dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3b4b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = [\n",
    "    MLPClassifier(random_state=1),\n",
    "\n",
    "    ]\n",
    "clf_columns = []\n",
    "clf_compare = pd.DataFrame(columns = clf_columns)\n",
    "\n",
    "row_index = 0\n",
    "for alg in clf:\n",
    "        \n",
    "    predicted = alg.fit(X_train, y_train).predict(X_test)\n",
    "    kf = KFold(n_splits=10)\n",
    "    y_train_pred = cross_val_predict(mlp_clf, X_train, y_train, cv=kf)\n",
    "    clf_name = alg.__class__.__name__\n",
    "    clf_compare.loc[row_index, 'Accuracy'] = accuracy_score(y_test, predicted )\n",
    "    tn, fp, fn, tp = confusion_matrix(y_train, y_train_pred).ravel()\n",
    "    clf_compare.loc[row_index, 'TN'] = tn\n",
    "    clf_compare.loc[row_index, 'FP'] = fp\n",
    "    clf_compare.loc[row_index, 'FN'] = fn\n",
    "    clf_compare.loc[row_index, 'TP'] = tp\n",
    "    clf_compare.loc[row_index, 'Sensitivity'] = tp / (tp + fn)\n",
    "    clf_compare.loc[row_index, 'Specificity'] = tn / (tn + fp)\n",
    "    clf_compare.loc[row_index, 'Precission'] = precision_score(y_train, y_train_pred, zero_division=0)\n",
    "    clf_compare.loc[row_index, 'Recall'] = recall_score(y_train, y_train_pred, zero_division=0)\n",
    "    fpr, tpr, thresholds = roc_curve(y_train, y_train_pred)\n",
    "    clf_compare.loc[row_index, 'AURC'] = roc_auc_score(y_train, y_train_pred)\n",
    "    row_index+=1\n",
    "    \n",
    "clf_compare.sort_values(by = ['Accuracy'], ascending = False, inplace = True)    \n",
    "clf_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34d4c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation treshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f89d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = [\n",
    "    MLPClassifier(random_state=1),\n",
    "\n",
    "    ]\n",
    "clf_columns = []\n",
    "clf_compare = pd.DataFrame(columns = clf_columns)\n",
    "\n",
    "row_index = 0\n",
    "for alg in clf:\n",
    "        \n",
    "    predicted = alg.fit(X_train, y_train).predict(X_test)\n",
    "    kf = KFold(n_splits=10)\n",
    "    y_train_pred = cross_val_predict(mlp_clf, X_train, y_train, cv=kf)\n",
    "    clf_name = alg.__class__.__name__\n",
    "    clf_compare.loc[row_index, 'Accuracy'] = accuracy_score(y_test, predicted )\n",
    "    tn, fp, fn, tp = confusion_matrix(y_train, y_train_pred).ravel()\n",
    "    clf_compare.loc[row_index, 'TN'] = tn\n",
    "    clf_compare.loc[row_index, 'FP'] = fp\n",
    "    clf_compare.loc[row_index, 'FN'] = fn\n",
    "    clf_compare.loc[row_index, 'TP'] = tp\n",
    "    clf_compare.loc[row_index, 'Sensitivity'] = tp / (tp + fn)\n",
    "    clf_compare.loc[row_index, 'Specificity'] = tn / (tn + fp)\n",
    "    clf_compare.loc[row_index, 'Precission'] = precision_score(y_train, y_train_pred, zero_division=0)\n",
    "    clf_compare.loc[row_index, 'Recall'] = recall_score(y_train, y_train_pred, zero_division=0)\n",
    "    fpr, tpr, thresholds = roc_curve(y_train, y_train_pred)\n",
    "    clf_compare.loc[row_index, 'AURC'] = roc_auc_score(y_train, y_train_pred)\n",
    "    row_index+=1\n",
    "    \n",
    "clf_compare.sort_values(by = ['Accuracy'], ascending = False, inplace = True)    \n",
    "clf_compare"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
